{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Grammar-Check.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vmZ0uz_443pL",
        "colab_type": "text"
      },
      "source": [
        "## Grammar-Checker"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DEfSbAA4QHas",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "39bc6d54-be6f-4223-e5b1-10aada84e20c"
      },
      "source": [
        "import tensorflow as tf\n",
        "device_name = tf.test.gpu_device_name()\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "# from google.colab import drive\n",
        "# drive.mount(\"/content/drive\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYsV4H8fCpZ-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "78721db4-562b-4ac3-9466-7e4da5ebaffc"
      },
      "source": [
        "import torch\n",
        "if torch.cuda.is_available():  \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print('No GPU available, using the CPU instead.')\n",
        "    device = torch.device(\"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla T4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pQf9LQPQ4ru9",
        "colab_type": "text"
      },
      "source": [
        "## Installing Hugging-Face"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G_N2UDLevYWn",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "Installing the [transformers](https://github.com/huggingface/transformers) package from Hugging Face which will give us a pytorch interface for working with BERT.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0NmMdkZO8R6q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 354
        },
        "outputId": "7997499b-ad5f-427d-afe5-bbcf02261145"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.1.0)\n",
            "Requirement already satisfied: tokenizers==0.8.1.rc2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8.1rc2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.91)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.16.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "guw6ZNtaswKc",
        "colab_type": "text"
      },
      "source": [
        "## Downloading the Dataset\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9ZKxKc04Btk",
        "colab_type": "text"
      },
      "source": [
        "We'll use [The Corpus of Linguistic Acceptability (CoLA)](https://nyu-mll.github.io/CoLA/) dataset.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5m6AnuFv0QXQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 33
        },
        "outputId": "2ad10b26-b186-4b81-cc21-7afa4656f0a9"
      },
      "source": [
        "!pip install wget\n",
        "import wget\n",
        "import os\n",
        "url = 'https://aman30865.github.io/cola_public_1.1.zip' #dataset hosted on my github\n",
        "if not os.path.exists('./cola_public_1.1.zip'):\n",
        "    wget.download(url, './cola_public_1.1.zip')\n",
        "\n",
        "if not os.path.exists('./cola_public/'):\n",
        "    !unzip cola_public_1.1.zip"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wget in /usr/local/lib/python3.6/dist-packages (3.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQUy9Tat2EF_",
        "colab_type": "text"
      },
      "source": [
        "##  Parsing the dataset Using Pandas"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_UkeC7SG2krJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "outputId": "2c37eafa-426b-45b2-b1a3-40157a01c728"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./cola_public/raw/in_domain_train.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "print('Number of training sentences: {:,}\\n'.format(df.shape[0]))\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "df.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of training sentences: 8,551\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence_source</th>\n",
              "      <th>label</th>\n",
              "      <th>label_notes</th>\n",
              "      <th>sentence</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Our friends won't buy this analysis, let alone...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization and I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>One more pseudo generalization or I'm giving up.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>The more we study verbs, the crazier they get.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>gj04</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>Day by day the facts are getting murkier.</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  sentence_source  ...                                           sentence\n",
              "0            gj04  ...  Our friends won't buy this analysis, let alone...\n",
              "1            gj04  ...  One more pseudo generalization and I'm giving up.\n",
              "2            gj04  ...   One more pseudo generalization or I'm giving up.\n",
              "3            gj04  ...     The more we study verbs, the crazier they get.\n",
              "4            gj04  ...          Day by day the facts are getting murkier.\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8kEDRvShcU5",
        "colab_type": "text"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bWOPOyWghJp2",
        "colab_type": "text"
      },
      "source": [
        "To feed our text to BERT, it must be split into tokens, and then these tokens must be mapped to their index in the tokenizer vocabulary.\n",
        "\n",
        "The tokenization must be performed by the tokenizer included with BERT--the below cell will download this for us. We'll be using the \"uncased\" version here.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z474sSC6oe7A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3d6f4f7d-57ea-4dc5-fb27-b817453cf1cb"
      },
      "source": [
        "#Loading the tokenizer for preprocessing\n",
        "from transformers import BertTokenizer\n",
        "print('Loading BERT tokenizer...')\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)\n",
        "print(\"Done\")"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading BERT tokenizer...\n",
            "Done\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l6w8elb-58GJ",
        "colab_type": "text"
      },
      "source": [
        "## Tokenize the dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2bBdb3pt8LuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 150
        },
        "outputId": "c530c620-b585-4e67-dc1a-b14570d68c02"
      },
      "source": [
        "input_ids = []\n",
        "attention_masks = []\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                      \n",
        "                        add_special_tokens = True, # Add '[CLS]' and '[SEP]'\n",
        "                        max_length = 64,           # Pad & truncate all sentences to 64 tokens.\n",
        "                        truncation = True,\n",
        "                        padding='max_length',\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,   # add attention masks.\n",
        "                        return_tensors = 'pt',\n",
        "                   )   \n",
        "    #making list of ids and masks\n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "# Convert the lists into tensors.\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "\n",
        "# Print sentence 0, now as a list of IDs.\n",
        "print('Original: ', sentences[6])\n",
        "print('Token IDs:', input_ids[6])"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Original:  Fred watered the plants flat.\n",
            "Token IDs: tensor([  101,  5965, 27129,  1996,  4264,  4257,  1012,   102,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aRp4O7D295d_",
        "colab_type": "text"
      },
      "source": [
        "## Splitting Dataset for training and validation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qu0ao7p8rb06",
        "colab_type": "text"
      },
      "source": [
        "Spliting our training set to use 90% for training and 10% for validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEgLpFVlo1Z-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "96d604f7-c51c-4d8c-82f6-63f61d53e58e"
      },
      "source": [
        "\n",
        "from torch.utils.data import TensorDataset, random_split\n",
        "dataset = TensorDataset(input_ids, attention_masks, labels)\n",
        "\n",
        "train_size = int(0.90 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "print('{:>5,} training samples'.format(train_size))\n",
        "print('{:>5,} validation samples'.format(val_size))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7,695 training samples\n",
            "  856 validation samples\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD9i6Z2pG-sN",
        "colab_type": "text"
      },
      "source": [
        "Using the torch DataLoader class that helps to save on memory during training because, unlike a for loop, with an iterator the entire dataset does not need to be loaded into memory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGUqOCtgqGhP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler\n",
        "\n",
        "batch_size = 32\n",
        "#for training\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = batch_size\n",
        "        )\n",
        "# for validation\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset, \n",
        "            sampler = SequentialSampler(val_dataset), \n",
        "            batch_size = batch_size\n",
        "        )"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXYitPoE-cjH",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "\n",
        "We have pre-trained BERT model and the additional untrained classification layer that will be trained and fined tuned according to out task. \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFsCTp_mporB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "41f1483d-465c-45e1-a55a-f36f49777ead"
      },
      "source": [
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    \"bert-base-uncased\", # 12-layer BERT model\n",
        "    num_labels = 2,    \n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "#use GPU\n",
        "model.cuda()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 768)\n",
              "      (token_type_embeddings): Embedding(2, 768)\n",
              "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qRWT-D4U_Pvx",
        "colab_type": "text"
      },
      "source": [
        "## Hyperparameter Tuning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8o-VEBobKwHk",
        "colab_type": "text"
      },
      "source": [
        "Setting the Adam optimizer and parameters as-\n",
        ">- **Batch size:** 32  \n",
        "- **Learning rate:** 2e-5  \n",
        "- **Number of epochs:** 4 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLs72DuMODJO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(),\n",
        "                  lr = 2e-5, \n",
        "                  eps = 1e-8 \n",
        "                )\n"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-p0upAhhRiIx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import get_linear_schedule_with_warmup\n",
        "\n",
        "epochs = 4\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = 0,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pE5B99H5H2-W",
        "colab_type": "text"
      },
      "source": [
        "Define a helper function for calculating accuracy."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cQNvaZ9bnyy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "# Function to calculate the accuracy\n",
        "def flat_accuracy(preds, labels):\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KNhRtWPXH9C3",
        "colab_type": "text"
      },
      "source": [
        "Helper function for formatting elapsed times as `hh:mm:ss`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gpt6tR83keZD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import datetime\n",
        "\n",
        "def format_time(elapsed):\n",
        "    '''\n",
        "    Takes a time in seconds and returns a string hh:mm:ss\n",
        "    '''\n",
        "    # Round to the nearest second.\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    \n",
        "    # Format as hh:mm:ss\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zTIYmnuoiiZ9",
        "colab_type": "text"
      },
      "source": [
        "# Training our model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6J-FYdx6nFE_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "outputId": "745ee1f2-1e06-4c5d-d9f1-30194ffe4ed8"
      },
      "source": [
        "import random\n",
        "import numpy as np\n",
        "seed_val = 34\n",
        "\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "\n",
        "training_stats = []\n",
        "\n",
        "total_t0 = time.time()\n",
        "#TRAINING\n",
        "# For each epoch\n",
        "for epoch_i in range(0, epochs):\n",
        "    \n",
        "    print(\"\")\n",
        "    print('======== Epoch {:} ========'.format(epoch_i + 1))\n",
        "\n",
        "    t0 = time.time()\n",
        "    total_train_loss = 0\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    # For each batch \n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "\n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        loss, logits = model(b_input_ids, \n",
        "                             token_type_ids=None, \n",
        "                             attention_mask=b_input_mask, \n",
        "                             labels=b_labels)\n",
        "\n",
        "        total_train_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_dataloader)            \n",
        "    \n",
        "    # Measure how long this epoch took.\n",
        "    training_time = format_time(time.time() - t0)\n",
        "\n",
        "    print(\"\")\n",
        "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
        "    print(\"  Training epcoh took: {:}\".format(training_time))\n",
        "        \n",
        "    # VALIDATION\n",
        "    print(\"\")\n",
        "    print(\"Running Validation...\")\n",
        "\n",
        "    t0 = time.time()\n",
        "\n",
        "    model.eval()\n",
        "\n",
        "    total_eval_accuracy = 0\n",
        "    total_eval_loss = 0\n",
        "    nb_eval_steps = 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        \n",
        "        \n",
        "        b_input_ids = batch[0].to(device)\n",
        "        b_input_mask = batch[1].to(device)\n",
        "        b_labels = batch[2].to(device)\n",
        "        \n",
        "        with torch.no_grad():        \n",
        "            (loss, logits) = model(b_input_ids, \n",
        "                                   token_type_ids=None, \n",
        "                                   attention_mask=b_input_mask,\n",
        "                                   labels=b_labels)\n",
        "            \n",
        "        total_eval_loss += loss.item()\n",
        "\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        total_eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "        \n",
        "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
        "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
        "\n",
        "    # Calculate the average loss over all of the batches.\n",
        "    avg_val_loss = total_eval_loss / len(validation_dataloader)\n",
        "    \n",
        "    # Measure how long the validation run took.\n",
        "    validation_time = format_time(time.time() - t0)\n",
        "    \n",
        "    print(\"  Validation Loss: {0:.2f}\".format(avg_val_loss))\n",
        "    print(\"  Validation took: {:}\".format(validation_time))\n",
        "\n",
        "    # Record all statistics from this epoch.\n",
        "    training_stats.append(\n",
        "        {\n",
        "            'epoch': epoch_i + 1,\n",
        "            'Training Loss': avg_train_loss,\n",
        "            'Valid. Loss': avg_val_loss,\n",
        "            'Valid. Accur.': avg_val_accuracy,\n",
        "            'Training Time': training_time,\n",
        "            'Validation Time': validation_time\n",
        "        }\n",
        "    )\n",
        "\n",
        "print(\"\")\n",
        "print(\"Training complete!\")\n",
        "\n",
        "print(\"Total training took {:} (h:mm:ss)\".format(format_time(time.time()-total_t0)))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "======== Epoch 1 ========\n",
            "\n",
            "  Average training loss: 0.50\n",
            "  Training epcoh took: 0:01:21\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.78\n",
            "  Validation Loss: 0.46\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 2 ========\n",
            "\n",
            "  Average training loss: 0.31\n",
            "  Training epcoh took: 0:01:25\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.80\n",
            "  Validation Loss: 0.51\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 3 ========\n",
            "\n",
            "  Average training loss: 0.20\n",
            "  Training epcoh took: 0:01:26\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.53\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "======== Epoch 4 ========\n",
            "\n",
            "  Average training loss: 0.14\n",
            "  Training epcoh took: 0:01:27\n",
            "\n",
            "Running Validation...\n",
            "  Accuracy: 0.81\n",
            "  Validation Loss: 0.60\n",
            "  Validation took: 0:00:03\n",
            "\n",
            "Training complete!\n",
            "Total training took 0:05:53 (h:mm:ss)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VQTvJ1vRP7u4",
        "colab_type": "text"
      },
      "source": [
        "## Summary of the training process."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6O_NbXFGMukX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 196
        },
        "outputId": "291291e2-0e5e-4bfe-e0fb-df70b5bba75f"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "pd.set_option('precision', 2)\n",
        "df_stats = pd.DataFrame(data=training_stats)\n",
        "df_stats = df_stats.set_index('epoch')\n",
        "df_stats"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Valid. Loss</th>\n",
              "      <th>Valid. Accur.</th>\n",
              "      <th>Training Time</th>\n",
              "      <th>Validation Time</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>epoch</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.50</td>\n",
              "      <td>0.46</td>\n",
              "      <td>0.78</td>\n",
              "      <td>0:01:21</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.31</td>\n",
              "      <td>0.51</td>\n",
              "      <td>0.80</td>\n",
              "      <td>0:01:25</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.20</td>\n",
              "      <td>0.53</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:01:26</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.14</td>\n",
              "      <td>0.60</td>\n",
              "      <td>0.81</td>\n",
              "      <td>0:01:27</td>\n",
              "      <td>0:00:03</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       Training Loss  Valid. Loss  Valid. Accur. Training Time Validation Time\n",
              "epoch                                                                         \n",
              "1               0.50         0.46           0.78       0:01:21         0:00:03\n",
              "2               0.31         0.51           0.80       0:01:25         0:00:03\n",
              "3               0.20         0.53           0.81       0:01:26         0:00:03\n",
              "4               0.14         0.60           0.81       0:01:27         0:00:03"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68xreA9JAmG5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 427
        },
        "outputId": "820b265b-b6f7-48b0-a07d-c21b9f2a3cd5"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "% matplotlib inline\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "# Use plot styling from seaborn.\n",
        "sns.set(style='darkgrid')\n",
        "\n",
        "# Increase the plot size and font size.\n",
        "sns.set(font_scale=1.5)\n",
        "plt.rcParams[\"figure.figsize\"] = (12,6)\n",
        "\n",
        "# Plot the learning curve.\n",
        "plt.plot(df_stats['Training Loss'], 'b-o', label=\"Training\")\n",
        "plt.plot(df_stats['Valid. Loss'], 'g-o', label=\"Validation\")\n",
        "\n",
        "# Label the plot.\n",
        "plt.title(\"Training & Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.legend()\n",
        "plt.xticks([1, 2, 3, 4])\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 864x432 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mkyubuJSOzg3",
        "colab_type": "text"
      },
      "source": [
        "## Performance On Test Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tg42jJqqM68F",
        "colab_type": "text"
      },
      "source": [
        "### Data Preparation\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xWe0_JW21MyV",
        "colab_type": "text"
      },
      "source": [
        "Test data preparation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN0LZBOOPVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "40c6b2cc-9a07-4c16-df65-c1561ad37da5"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv(\"./cola_public/raw/out_of_domain_dev.tsv\", delimiter='\\t', header=None, names=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "print('Number of test sentences: {:,}\\n'.format(df.shape[0]))\n",
        "sentences = df.sentence.values\n",
        "labels = df.label.values\n",
        "input_ids = []\n",
        "attention_masks = []\n",
        "\n",
        "# For every sentence...\n",
        "for sent in sentences:\n",
        "    encoded_dict = tokenizer.encode_plus(\n",
        "                        sent,                    \n",
        "                        add_special_tokens = True, \n",
        "                        max_length = 64,          \n",
        "                        truncation =True,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt', \n",
        "                   )  \n",
        "    input_ids.append(encoded_dict['input_ids'])\n",
        "    attention_masks.append(encoded_dict['attention_mask'])\n",
        "\n",
        "input_ids = torch.cat(input_ids, dim=0)\n",
        "attention_masks = torch.cat(attention_masks, dim=0)\n",
        "labels = torch.tensor(labels)\n",
        "batch_size = 32  \n",
        "\n",
        "# Create the DataLoader.\n",
        "prediction_data = TensorDataset(input_ids, attention_masks, labels)\n",
        "prediction_sampler = SequentialSampler(prediction_data)\n",
        "prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Number of test sentences: 516\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16lctEOyNFik",
        "colab_type": "text"
      },
      "source": [
        "##  Evaluate on Test Set\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhR99IISNMg9",
        "colab_type": "text"
      },
      "source": [
        "Generating predictions on the test set.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hba10sXR7Xi6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "a993002f-20b8-4861-f8e3-5a8bc83db712"
      },
      "source": [
        "print('Predicting labels for {:,} test sentences...'.format(len(input_ids)))\n",
        "\n",
        "# Put model in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "predictions , true_labels = [], []\n",
        "\n",
        "# Predict \n",
        "for batch in prediction_dataloader:\n",
        "  batch = tuple(t.to(device) for t in batch)\n",
        "  b_input_ids, b_input_mask, b_labels = batch\n",
        "  with torch.no_grad():\n",
        "      outputs = model(b_input_ids, token_type_ids=None, \n",
        "                      attention_mask=b_input_mask)\n",
        "\n",
        "  logits = outputs[0]\n",
        "\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  label_ids = b_labels.to('cpu').numpy()\n",
        "  \n",
        "  # Store predictions and true labels\n",
        "  predictions.append(logits)\n",
        "  true_labels.append(label_ids)\n",
        "\n",
        "print('DONE.')"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Predicting labels for 516 test sentences...\n",
            "DONE.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-5jscIM8R4Gv",
        "colab_type": "text"
      },
      "source": [
        "Accuracy on the CoLA benchmark is measured using the \"[Matthews correlation coefficient](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.matthews_corrcoef.html)\" (MCC).\n",
        "\n",
        "We use MCC here because the classes are imbalanced:\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cRaZQ4XC7kLs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "4f59654f-3d51-45c3-a7e0-1d9fbc227dea"
      },
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "matthews_set = []\n",
        "\n",
        "\n",
        "print('Calculating Matthews Corr. Coef. for each batch...')\n",
        "\n",
        "for i in range(len(true_labels)):\n",
        "  pred_labels_i = np.argmax(predictions[i], axis=1).flatten()\n",
        "  matthews = matthews_corrcoef(true_labels[i], pred_labels_i)                \n",
        "  matthews_set.append(matthews)\n",
        "\n",
        "flat_predictions = np.concatenate(predictions, axis=0)\n",
        "flat_predictions = np.argmax(flat_predictions, axis=1).flatten()\n",
        "flat_true_labels = np.concatenate(true_labels, axis=0)\n",
        "\n",
        "# Calculate the MCC\n",
        "mcc = matthews_corrcoef(flat_true_labels, flat_predictions)\n",
        "\n",
        "print('Total MCC: %.3f' % mcc)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Calculating Matthews Corr. Coef. for each batch...\n",
            "Total MCC: 0.519\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q2079Qyn8Mt8",
        "colab_type": "text"
      },
      "source": [
        "##  Saving\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6ulTWaOr8QNY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67
        },
        "outputId": "6eace22d-fc7b-4f31-afc5-4dabbe493d8e"
      },
      "source": [
        "import os\n",
        "\n",
        "output_dir = '/content/saved_model'\n",
        "if not os.path.exists(output_dir):\n",
        "    os.makedirs(output_dir) #Creating required directory\n",
        "model_to_save = model.module if hasattr(model, 'module') else model\n",
        "model_to_save.save_pretrained(output_dir)\n",
        "tokenizer.save_pretrained(output_dir)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('/content/saved_model/vocab.txt',\n",
              " '/content/saved_model/special_tokens_map.json',\n",
              " '/content/saved_model/added_tokens.json')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tPZp77CiNCDj",
        "colab_type": "text"
      },
      "source": [
        "## Prediction"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZDoyjyA79C9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from transformers import BertForSequenceClassification\n",
        "from transformers import BertTokenizer\n",
        "import torch\n",
        "\n",
        "output_dir = '/content/saved_model' # or https://drive.google.com/drive/folders/1gBtM3ifYsrZ70ZmNW1hj-pb-dxvd2n3b?usp=sharing\n",
        "tokenizer = BertTokenizer.from_pretrained(output_dir)\n",
        "model_loaded = BertForSequenceClassification.from_pretrained(output_dir)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvmqzSRvnQGh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 117
        },
        "outputId": "005308d0-ee27-4190-dc47-6b0a7e056283"
      },
      "source": [
        "again = 1\n",
        "while(again):\n",
        "  sent = input()\n",
        "  encoded_dict = tokenizer.encode_plus(\n",
        "                          sent,\n",
        "                          add_special_tokens = True,\n",
        "                          max_length = 64,\n",
        "                          truncation=True,\n",
        "                          padding='max_length',\n",
        "                          return_attention_mask = True,\n",
        "                          return_tensors = 'pt',\n",
        "                    )\n",
        "  input_id = encoded_dict['input_ids']\n",
        "  attention_mask = encoded_dict['attention_mask']\n",
        "  input_id = torch.LongTensor(input_id)\n",
        "  attention_mask = torch.LongTensor(attention_mask)\n",
        "  device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "  model_loaded = model_loaded.to(device)\n",
        "  input_id = input_id.to(device)\n",
        "  attention_mask = attention_mask.to(device)\n",
        "  with torch.no_grad():\n",
        "    outputs = model_loaded(input_id, token_type_ids=None, attention_mask=attention_mask)\n",
        "  logits = outputs[0]\n",
        "  index = logits.argmax()\n",
        "  if index == 1:\n",
        "    print(\"The given sentence is Gramatically correct\")\n",
        "  else:\n",
        "    print(\"The given sentence is Gramatically in-correct\")\n",
        "  again=int(input(\"Enter 1 to Continue or 0 to Exit:\"))\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "I am going\n",
            "The given sentence is Gramatically correct\n",
            "Enter 1 to Continue or 0 to Exit:1\n",
            "I am go\n",
            "The given sentence is Gramatically in-correct\n",
            "Enter 1 to Continue or 0 to Exit:0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}